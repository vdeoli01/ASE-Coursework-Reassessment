- Using the command: python tournament.py 2018m.csv

Times:

10 simulations: 0m0.018s (record time using 0m0.000s format)
100 simulations: 0m0.020s (record time using 0m0.000s format)
1000 simulations: 0m0.025s (record time using 0m0.000s format)
10000 simulations: 0m0.080s (record time using 0m0.000s format)
100000 simulations: 0m0.644s (record time using 0m0.000s format)
1000000 simulations: 0m6.441s (record time using 0m0.000s format)

Questions:

Which predictions, if any, proved incorrect as you increased the number of simulations?: TODO
- 

Suppose you're charged a fee for each second of compute time your program uses.
After how many simulations would you call the predictions "good enough"?: TODO

- This all depends on what the predictions are used for 
- If the aim is to just predict the winner then this might be able to be done in fewer simluations than predicting each teams winning chances accuratley
- In order to deduce the latter case the most efficient solution would be to keep simulating tournaments till the order of teams stayed the same (stabilised) between simulations.
  At this point you know your predictions are good enough.
- In our case this was between 1,000 and 10,000 the order of teams stabilised